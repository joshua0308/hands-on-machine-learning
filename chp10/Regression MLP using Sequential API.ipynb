{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pydot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup early stop callback\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "363/363 [==============================] - 0s 802us/step - loss: 1.4971 - val_loss: 0.5293\n",
      "Epoch 2/200\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.5242 - val_loss: 0.4521\n",
      "Epoch 3/200\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.4410 - val_loss: 0.4244\n",
      "Epoch 4/200\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.4207 - val_loss: 0.4201\n",
      "Epoch 5/200\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.4107 - val_loss: 0.4067\n",
      "Epoch 6/200\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.4004 - val_loss: 0.3987\n",
      "Epoch 7/200\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3892 - val_loss: 0.3971\n",
      "Epoch 8/200\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.3886 - val_loss: 0.4000\n",
      "Epoch 9/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3708 - val_loss: 0.3838\n",
      "Epoch 10/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3806 - val_loss: 0.3815\n",
      "Epoch 11/200\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.3779 - val_loss: 0.3793\n",
      "Epoch 12/200\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3722 - val_loss: 0.3798\n",
      "Epoch 13/200\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.3747 - val_loss: 0.3749\n",
      "Epoch 14/200\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.3794 - val_loss: 0.3730\n",
      "Epoch 15/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3665 - val_loss: 0.3848\n",
      "Epoch 16/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3711 - val_loss: 0.3797\n",
      "Epoch 17/200\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.3694 - val_loss: 0.3671\n",
      "Epoch 18/200\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.3598 - val_loss: 0.3691\n",
      "Epoch 19/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3534 - val_loss: 0.3654\n",
      "Epoch 20/200\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.3506 - val_loss: 0.3647\n",
      "Epoch 21/200\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.3611 - val_loss: 0.3635\n",
      "Epoch 22/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3486 - val_loss: 0.3611\n",
      "Epoch 23/200\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.3437 - val_loss: 0.3608\n",
      "Epoch 24/200\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.3528 - val_loss: 0.3598\n",
      "Epoch 25/200\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3516 - val_loss: 0.3592\n",
      "Epoch 26/200\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.3556 - val_loss: 0.3586\n",
      "Epoch 27/200\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.3574 - val_loss: 0.3541\n",
      "Epoch 28/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3496 - val_loss: 0.3528\n",
      "Epoch 29/200\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.3470 - val_loss: 0.3514\n",
      "Epoch 30/200\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.3346 - val_loss: 0.3532\n",
      "Epoch 31/200\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3449 - val_loss: 0.3515\n",
      "Epoch 32/200\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.3674 - val_loss: 0.3520\n",
      "Epoch 33/200\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.3300 - val_loss: 0.3493\n",
      "Epoch 34/200\n",
      "363/363 [==============================] - 0s 603us/step - loss: 0.3356 - val_loss: 0.3493\n",
      "Epoch 35/200\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.3330 - val_loss: 0.3671\n",
      "Epoch 36/200\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.3276 - val_loss: 0.3452\n",
      "Epoch 37/200\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3232 - val_loss: 0.3475\n",
      "Epoch 38/200\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.3372 - val_loss: 0.3451\n",
      "Epoch 39/200\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.3349 - val_loss: 0.3469\n",
      "Epoch 40/200\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3296 - val_loss: 0.3383\n",
      "Epoch 41/200\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3282 - val_loss: 0.3378\n",
      "Epoch 42/200\n",
      "363/363 [==============================] - 0s 560us/step - loss: 0.3218 - val_loss: 0.3455\n",
      "Epoch 43/200\n",
      "363/363 [==============================] - 0s 552us/step - loss: 0.3509 - val_loss: 0.3371\n",
      "Epoch 44/200\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3266 - val_loss: 0.3366\n",
      "Epoch 45/200\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3306 - val_loss: 0.3379\n",
      "Epoch 46/200\n",
      "363/363 [==============================] - 0s 545us/step - loss: 0.3317 - val_loss: 0.3481\n",
      "Epoch 47/200\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.3150 - val_loss: 0.3320\n",
      "Epoch 48/200\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.3305 - val_loss: 0.3316\n",
      "Epoch 49/200\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3187 - val_loss: 0.3326\n",
      "Epoch 50/200\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.3409 - val_loss: 0.3508\n",
      "Epoch 51/200\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3294 - val_loss: 0.3346\n",
      "Epoch 52/200\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.3253 - val_loss: 0.3446\n",
      "Epoch 53/200\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.3310 - val_loss: 0.3331\n",
      "Epoch 54/200\n",
      "363/363 [==============================] - 0s 603us/step - loss: 0.3136 - val_loss: 0.3232\n",
      "Epoch 55/200\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3256 - val_loss: 0.3280\n",
      "Epoch 56/200\n",
      "363/363 [==============================] - 0s 545us/step - loss: 0.3148 - val_loss: 0.3246\n",
      "Epoch 57/200\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.2954 - val_loss: 0.3329\n",
      "Epoch 58/200\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.3087 - val_loss: 0.3214\n",
      "Epoch 59/200\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3100 - val_loss: 0.3333\n",
      "Epoch 60/200\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.3144 - val_loss: 0.3255\n",
      "Epoch 61/200\n",
      "363/363 [==============================] - 0s 603us/step - loss: 0.3244 - val_loss: 0.3261\n",
      "Epoch 62/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3125 - val_loss: 0.3301\n",
      "Epoch 63/200\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3188 - val_loss: 0.3210\n",
      "Epoch 64/200\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3153 - val_loss: 0.3213\n",
      "Epoch 65/200\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.3214 - val_loss: 0.3273\n",
      "Epoch 66/200\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.3209 - val_loss: 0.3345\n",
      "Epoch 67/200\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.3174 - val_loss: 0.3210\n",
      "Epoch 68/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3157 - val_loss: 0.3303\n",
      "Epoch 69/200\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.3180 - val_loss: 0.3300\n",
      "Epoch 70/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3086 - val_loss: 0.3198\n",
      "Epoch 71/200\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.3295 - val_loss: 0.3206\n",
      "Epoch 72/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3111 - val_loss: 0.3150\n",
      "Epoch 73/200\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.3192 - val_loss: 0.3552\n",
      "Epoch 74/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3097 - val_loss: 0.3206\n",
      "Epoch 75/200\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.3087 - val_loss: 0.3281\n",
      "Epoch 76/200\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3079 - val_loss: 0.3151\n",
      "Epoch 77/200\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3096 - val_loss: 0.3198\n",
      "Epoch 78/200\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.3104 - val_loss: 0.3242\n",
      "Epoch 79/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3188 - val_loss: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.3086 - val_loss: 0.3196\n",
      "Epoch 81/200\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3008 - val_loss: 0.3146\n",
      "Epoch 82/200\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.3095 - val_loss: 0.3137\n",
      "Epoch 83/200\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.3066 - val_loss: 0.3124\n",
      "Epoch 84/200\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.3082 - val_loss: 0.3227\n",
      "Epoch 85/200\n",
      "363/363 [==============================] - 0s 521us/step - loss: 0.3004 - val_loss: 0.3248\n",
      "Epoch 86/200\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.2899 - val_loss: 0.3206\n",
      "Epoch 87/200\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.2914 - val_loss: 0.3114\n",
      "Epoch 88/200\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3110 - val_loss: 0.3300\n",
      "Epoch 89/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3068 - val_loss: 0.3176\n",
      "Epoch 90/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3098 - val_loss: 0.3130\n",
      "Epoch 91/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3001 - val_loss: 0.3076\n",
      "Epoch 92/200\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3041 - val_loss: 0.3113\n",
      "Epoch 93/200\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.3084 - val_loss: 0.3097\n",
      "Epoch 94/200\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.2898 - val_loss: 0.3134\n",
      "Epoch 95/200\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.2928 - val_loss: 0.3283\n",
      "Epoch 96/200\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.2997 - val_loss: 0.3093\n",
      "Epoch 97/200\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3043 - val_loss: 0.3090\n",
      "Epoch 98/200\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.2939 - val_loss: 0.3121\n",
      "Epoch 99/200\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.2989 - val_loss: 0.3108\n",
      "Epoch 100/200\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.3046 - val_loss: 0.3098\n",
      "Epoch 101/200\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.2992 - val_loss: 0.3230\n"
     ]
    }
   ],
   "source": [
    "# setup tensorboard callback\n",
    "root_logdir = os.path.join(os.curdir, \"logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, epochs=200, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    callbacks=[tensorboard_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 445us/step - loss: 0.3142\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
